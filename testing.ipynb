{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[16034596.log: 10-03 14:18:02] p51148 {/data/vision/torralba/dissect/nadiia/adversarial_research/utils/util_functions.py:142} DEBUG - Data dir path /data/vision/torralba/dissect/nadiia/adversarial_research/datasets/places/val\n",
      "[16034596.log: 10-03 14:18:02] p51148 {/data/vision/torralba/dissect/nadiia/adversarial_research/utils/util_functions.py:143} DEBUG - Creating dataset with batch_size 150, num_workers=0\n",
      "[16034596.log: 10-03 14:18:02] p51148 {/data/vision/torralba/dissect/nadiia/adversarial_research/utils/util_functions.py:79} DEBUG - Creating transformer with crop_size=224, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)\n",
      "[16034596.log: 10-03 14:18:02] p51148 {/data/vision/torralba/dissect/nadiia/adversarial_research/utils/util_functions.py:124} DEBUG - Loading dataset from folder /data/vision/torralba/dissect/nadiia/adversarial_research/datasets/places/val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started...\n",
      "attempt = 0\n",
      "*** model resnet18 ***\n",
      "it 32768\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 460.00 MiB (GPU 0; 23.65 GiB total capacity; 18.47 GiB already allocated; 83.00 MiB free; 19.45 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-808c10ac7887>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_batch_alex\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"alex\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmod\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mimage_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0mpredcat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mcorrect_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredcat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/my_nfs/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/my_nfs/miniconda3/lib/python3.8/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/my_nfs/miniconda3/lib/python3.8/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;31m# See note [TorchScript super()]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/my_nfs/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/my_nfs/miniconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/my_nfs/miniconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    413\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 415\u001b[0;31m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0m\u001b[1;32m    416\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 460.00 MiB (GPU 0; 23.65 GiB total capacity; 18.47 GiB already allocated; 83.00 MiB free; 19.45 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from adversarial_attacks import test\n",
    "from utils import util_functions as uf\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import argparse\n",
    "import cv2\n",
    "print(\"Started...\")\n",
    "\n",
    "models = [\n",
    "#    \"alexnet\", \n",
    "    \"resnet18\", \n",
    "#    \"softalexnet\", \n",
    "    \"softresnet18\"\n",
    "]\n",
    "\n",
    "iters = [32768, 38868, 46241, 55009, 92582, 110218, 185264]\n",
    "epsilons = [0.0001, 0.001, 0.01, 0.1]\n",
    "\n",
    "BATCH_SIZE = 150\n",
    "MIN_EXAMPLES = 50\n",
    "train_len = \"long\"\n",
    "iter_prefix = \"best_iter\"\n",
    "\n",
    "pos = len(iter_prefix.split(\"_\"))\n",
    "\n",
    "def list_dirs(_model):\n",
    "    p = \"checkpoints/{}_trained/{}\".format(train_len, _model)\n",
    "    ll = [x for x in os.listdir(p) if iter_prefix in x]\n",
    "    ll = [int(x.split(\"_\")[pos]) for x in ll]\n",
    "    ll = sorted(ll)\n",
    "    return ll\n",
    "\n",
    "def get_image_both_sizes(dataset=\"places\", val=True):\n",
    "    image_batch, labels, orig_paths, names, \\\n",
    "    cats, orig_images, catlist = test.get_batch(\"resnet18\",\n",
    "                                                batch_size=BATCH_SIZE)\n",
    "    paths = orig_paths[0]\n",
    "    base = uf.find_child_dir_path(\"datasets\")\n",
    "    basepath_val = os.path.join(base, dataset, \"val\")\n",
    "    basepath_train = os.path.join(base, dataset, \"train\")\n",
    "    image_batch_alex, labels_alex, paths = \\\n",
    "        uf.get_image_as_batch(paths=tuple(paths),\n",
    "                              val_data_folder=basepath_val,\n",
    "                              train_data_fold=basepath_train,\n",
    "                              val=val, model=\"alexnet\",\n",
    "                              batch_size=BATCH_SIZE)\n",
    "    image_batch_alex, labels_alex = image_batch_alex.cuda(), labels_alex.cuda()\n",
    "    lbls_sorted, _ = torch.sort(labels)\n",
    "    lbls_alex_sorted, _ = torch.sort(labels_alex)\n",
    "    assert torch.equal(lbls_sorted, lbls_alex_sorted)\n",
    "    return image_batch_alex, image_batch, labels, orig_paths\n",
    "\n",
    "\n",
    "image_batch_alex, image_batch, labels, orig_paths = None, None, None, None\n",
    "attempt = 0\n",
    "\n",
    "#find image that is classified correctly for all models and iters\n",
    "while attempt < 50:\n",
    "    print(\"attempt = {}\".format(attempt))\n",
    "    image_batch_alex, image_batch, labels, orig_paths = get_image_both_sizes()\n",
    "    attempt += 1\n",
    "    failed = False\n",
    "    for mod in models:\n",
    "        print(\"*** model {} ***\".format(mod))\n",
    "        for it in iters:\n",
    "            print(\"it {}\".format(it))\n",
    "            \n",
    "            model = uf.get_model_arg(mod, it, longtrain=train_len==\"long\")\n",
    "            model.eval()\n",
    "            model.cuda()\n",
    "            batch = image_batch_alex if \"alex\" in mod else image_batch\n",
    "            out = model(batch.cuda())\n",
    "            predcat = torch.argmax(out, dim=1)\n",
    "            correct_imgs = torch.flatten(torch.nonzero(predcat == labels))\n",
    "            batch = batch[correct_imgs]\n",
    "\n",
    "            print(\"Remained {} imgs, need at least {}\".format(\n",
    "                batch.shape[0], MIN_EXAMPLES))\n",
    "\n",
    "            if batch.shape[0] < MIN_EXAMPLES:\n",
    "                print(\"failed!\")\n",
    "                failed = True\n",
    "                break\n",
    "        if failed is True:\n",
    "            break\n",
    "    if failed is False:\n",
    "        break\n",
    "\n",
    "\n",
    "print(\"Batched picked!\")\n",
    "\n",
    "if attempt >= 50:\n",
    "    print(\"Didn't find an image with correct classification!\")\n",
    "    exit()\n",
    "\n",
    "rows = 1\n",
    "cols = 2\n",
    "figsize = (cols * 8, rows * 5)\n",
    "fig, axs = plt.subplots(rows, cols, figsize=figsize)\n",
    "mid = (fig.subplotpars.right + fig.subplotpars.left) / 2\n",
    "plt.subplots_adjust(left=None, bottom=None, right=None, top=1.2,\n",
    "                    wspace=None, hspace=None)\n",
    "plt.suptitle(\"# imgs {}\".format(image_batch.shape[0]), x=mid, y=1)\n",
    "\n",
    "print(\"Starting attacks...\")\n",
    "\n",
    "for i, mod in enumerate(models):\n",
    "    accs = []\n",
    "    ax = axs[i]\n",
    "    for it in iters:\n",
    "        epsilons, robust_accuracy, raw, clipped, \\\n",
    "            is_adv, (predcat, adv_predcat, label) = test.run_attacks(mod, it,\n",
    "                image_batch if \"alexnet\" not in mod else image_batch_alex,\n",
    "                labels, attack_name=\"PGD\", longtrain=train_len==\"long\",\n",
    "                epsilons=epsilons)\n",
    "\n",
    "        accs.append(robust_accuracy)\n",
    "\n",
    "    ax.set_title(mod)\n",
    "    for j, ep in enumerate(epsilons):\n",
    "        ax.plot(iters, [x[j] for x in accs], label=\"it {}\".format(it))\n",
    "\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (DatabaseError('database disk image is malformed')).History will not be written to the database.\n",
      "[0, 1, 509, 624, 861, 1118, 1348, 1448, 1622, 1722, 1948, 2048, 2335, 2435, 2796, 2896, 3344, 3444, 3996, 4771, 5693, 5793, 6789, 9642, 9742, 11585, 13677, 16284, 19384, 19484, 23070, 23170, 27454, 27554, 32668, 32768, 38868, 38968, 46241, 65536, 77836, 77936, 110118, 130972, 185264]\n",
      "[0, 5, 6, 8, 10, 54, 64, 76, 91, 108, 128, 152, 181, 204, 215, 256, 262, 304, 331, 362, 412, 431, 509, 512, 609, 624, 724, 761, 861, 924, 1118, 1218, 1348, 1448, 1622, 1722, 1948, 2335, 2435, 2796, 2896, 3344, 3444, 3996, 4096, 4771, 4871, 5693, 5793, 6789, 6889, 8092, 9642, 9742, 11485, 13677, 13777, 19384, 27454, 32768, 38868, 65536, 92582, 155872, 524188]\n",
      "185264\n"
     ]
    }
   ],
   "source": [
    "ll1 = list_dirs(\"softresnet18\")\n",
    "ll2 = list_dirs(\"softalexnet\")\n",
    "ll3 = list_dirs(\"alexnet\")\n",
    "ll4 = list_dirs(\"resnet18\")\n",
    "print(ll3)\n",
    "print(ll4)\n",
    "mi = min([\n",
    "    # ll1[-1],\n",
    "    # ll2[-1],\n",
    "    ll3[-1],\n",
    "    ll4[-1]\n",
    "])\n",
    "print(mi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
